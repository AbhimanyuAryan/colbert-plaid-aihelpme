{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _auto_detect_device() -> str:\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseReranker(ABC):\n",
    "    def _detect_device(self, device: str) -> str:\n",
    "        if device == \"auto\":\n",
    "            device = _auto_detect_device()\n",
    "        return device\n",
    "\n",
    "    def rerank(self, query: str, documents: list[str]) -> tuple[list[int], list[float]]:\n",
    "        scores = self._rerank(query, documents)\n",
    "        indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=False)\n",
    "        return indices, scores\n",
    "\n",
    "    @abstractmethod\n",
    "    def _rerank(self, query: str, documents: list[str]) -> list[float]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _insert_token(\n",
    "    output: dict,\n",
    "    insert_token_id: int,\n",
    "    insert_position: int = 1,\n",
    "    token_type_id: int = 0,\n",
    "    attention_value: int = 1,\n",
    "):\n",
    "    updated_output = {}\n",
    "    for key in output:\n",
    "        updated_tensor_list = []\n",
    "        for seqs in output[key]:\n",
    "            if len(seqs.shape) == 1:\n",
    "                seqs = seqs.unsqueeze(0)\n",
    "            for seq in seqs:\n",
    "                first_part = seq[:insert_position]\n",
    "                second_part = seq[insert_position:]\n",
    "                new_element = (\n",
    "                    torch.tensor([insert_token_id])\n",
    "                    if key == \"input_ids\"\n",
    "                    else torch.tensor([token_type_id])\n",
    "                )\n",
    "                if key == \"attention_mask\":\n",
    "                    new_element = torch.tensor([attention_value])\n",
    "                updated_seq = torch.cat((first_part, new_element, second_part), dim=0)\n",
    "                updated_tensor_list.append(updated_seq)\n",
    "        updated_output[key] = torch.stack(updated_tensor_list)\n",
    "    return updated_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _colbert_score(q_reps, p_reps, q_mask: torch.Tensor, p_mask: torch.Tensor):\n",
    "    # calc max sim\n",
    "    token_scores = torch.einsum(\"qin,pjn->qipj\", q_reps, p_reps)\n",
    "    token_scores = token_scores.masked_fill(p_mask.unsqueeze(0).unsqueeze(0) == 0, -1e4)\n",
    "    scores, _ = token_scores.max(-1)\n",
    "    scores = scores.sum(1) / q_mask[:, 1:].sum(-1, keepdim=True)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColbertReranker(BaseReranker):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        device: str = \"auto\",\n",
    "        use_fp16=True,\n",
    "        max_length=512,\n",
    "        query_token: str = \"[unused0]\",\n",
    "        document_token: str = \"[unused1]\",\n",
    "        normalize: bool = True,\n",
    "    ):\n",
    "        device = self._detect_device(device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.device = device\n",
    "        self.model.to(device)\n",
    "        if use_fp16 and \"cuda\" in device:\n",
    "            self.model.half()\n",
    "        self.model.eval()\n",
    "        self.model.max_length = max_length\n",
    "        self.max_length = max_length\n",
    "        self.query_token_id: int = self.tokenizer.convert_tokens_to_ids(query_token)  # type: ignore\n",
    "        self.document_token_id: int = self.tokenizer.convert_tokens_to_ids(document_token)  # type: ignore\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def _encode(self, texts: list[str], insert_token_id: int):\n",
    "        encoding = self.tokenizer(\n",
    "            texts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            max_length=self.max_length - 1,  # for insert token\n",
    "            truncation=True,\n",
    "        )\n",
    "        encoding = _insert_token(encoding, insert_token_id)  # type: ignore\n",
    "        encoding = {key: value.to(self.device) for key, value in encoding.items()}\n",
    "        return encoding\n",
    "\n",
    "    def _query_encode(self, query: list[str]):\n",
    "        return self._encode(query, self.query_token_id)\n",
    "\n",
    "    def _document_encode(self, documents: list[str]):\n",
    "        return self._encode(documents, self.document_token_id)\n",
    "\n",
    "    def _to_embs(self, encoding) -> torch.Tensor:\n",
    "        with torch.no_grad():\n",
    "            embs = self.model(**encoding).last_hidden_state.squeeze(1)\n",
    "        if self.normalize:\n",
    "            embs = embs / embs.norm(dim=-1, keepdim=True)\n",
    "        return embs\n",
    "\n",
    "    def _rerank(self, query: str, documents: list[str]) -> list[float]:\n",
    "        query_encoding = self._query_encode([query])\n",
    "        documents_encoding = self._document_encode(documents)\n",
    "        query_embeddings = self._to_embs(query_encoding)\n",
    "        document_embeddings = self._to_embs(documents_encoding)\n",
    "        scores = (\n",
    "            _colbert_score(\n",
    "                query_embeddings,\n",
    "                document_embeddings,\n",
    "                query_encoding[\"attention_mask\"],\n",
    "                documents_encoding[\"attention_mask\"],\n",
    "            )\n",
    "            .cpu()\n",
    "            .tolist()[0]\n",
    "        )\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"colbert-ir/colbertv2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker = ColbertReranker(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is natural language processing?\"\n",
    "documents = [\n",
    "    \"Natural language processing enables computers to understand human language.\",\n",
    "    \"Machine learning involves teaching computers to learn from data.\",\n",
    "    \"The history of natural language processing is closely linked to the field of linguistics.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, scores = reranker.rerank(query, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 Score: 0.950442910194397\n",
      "Content: Machine learning involves teaching computers to learn from data.\n",
      "\n",
      "Document 2 Score: 0.5879635214805603\n",
      "Content: The history of natural language processing is closely linked to the field of linguistics.\n",
      "\n",
      "Document 0 Score: 0.8569756746292114\n",
      "Content: Natural language processing enables computers to understand human language.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, score in zip(indices, scores):\n",
    "    print(f\"Document {idx} Score: {score}\")\n",
    "    print(f\"Content: {documents[idx]}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

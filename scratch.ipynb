{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _auto_detect_device() -> str:\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_auto_detect_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseReranker(ABC):\n",
    "    def _detect_device(self, device: str) -> str:\n",
    "        if device == \"auto\":\n",
    "            device = _auto_detect_device()\n",
    "        return device\n",
    "\n",
    "    def rerank(self, query: str, documents: list[str]) -> tuple[list[int], list[float]]:\n",
    "        scores = self._rerank(query, documents)\n",
    "        indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=False)\n",
    "        return indices, scores\n",
    "\n",
    "    @abstractmethod\n",
    "    def _rerank(self, query: str, documents: list[str]) -> list[float]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _insert_token(\n",
    "    output: dict,\n",
    "    insert_token_id: int,\n",
    "    insert_position: int = 1,\n",
    "    token_type_id: int = 0,\n",
    "    attention_value: int = 1,\n",
    "):\n",
    "    updated_output = {}\n",
    "    for key in output:\n",
    "        updated_tensor_list = []\n",
    "        for seqs in output[key]:\n",
    "            if len(seqs.shape) == 1:\n",
    "                seqs = seqs.unsqueeze(0)\n",
    "            for seq in seqs:\n",
    "                first_part = seq[:insert_position]\n",
    "                second_part = seq[insert_position:]\n",
    "                new_element = (\n",
    "                    torch.tensor([insert_token_id])\n",
    "                    if key == \"input_ids\"\n",
    "                    else torch.tensor([token_type_id])\n",
    "                )\n",
    "                if key == \"attention_mask\":\n",
    "                    new_element = torch.tensor([attention_value])\n",
    "                updated_seq = torch.cat((first_part, new_element, second_part), dim=0)\n",
    "                updated_tensor_list.append(updated_seq)\n",
    "        updated_output[key] = torch.stack(updated_tensor_list)\n",
    "    return updated_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _colbert_score(q_reps, p_reps, q_mask: torch.Tensor, p_mask: torch.Tensor):\n",
    "    print(\"shape of q_reps, p_reps, q_mask, p_mask\")\n",
    "    print(q_reps.shape, p_reps.shape, q_mask.shape, p_mask.shape)\n",
    "    print(q_reps, p_reps, q_mask, p_mask)\n",
    "\n",
    "    # calc max sim\n",
    "    token_scores = torch.einsum(\"qin,pjn->qipj\", q_reps, p_reps)\n",
    "    token_scores = token_scores.masked_fill(p_mask.unsqueeze(0).unsqueeze(0) == 0, -1e4)\n",
    "    scores, _ = token_scores.max(-1)\n",
    "    scores = scores.sum(1) / q_mask[:, 1:].sum(-1, keepdim=True)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColbertReranker(BaseReranker):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        device: str = \"auto\",\n",
    "        use_fp16=True,\n",
    "        max_length=512,\n",
    "        query_token: str = \"[unused0]\",\n",
    "        document_token: str = \"[unused1]\",\n",
    "        normalize: bool = True,\n",
    "    ):\n",
    "        device = self._detect_device(device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.device = device\n",
    "        self.model.to(device)\n",
    "        if use_fp16 and \"cuda\" in device:\n",
    "            self.model.half()\n",
    "        self.model.eval()\n",
    "        self.model.max_length = max_length\n",
    "        self.max_length = max_length\n",
    "        self.query_token_id: int = self.tokenizer.convert_tokens_to_ids(query_token)  # type: ignore\n",
    "        self.document_token_id: int = self.tokenizer.convert_tokens_to_ids(document_token)  # type: ignore\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def _encode(self, texts: list[str], insert_token_id: int):\n",
    "        encoding = self.tokenizer(\n",
    "            texts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            max_length=self.max_length - 1,  # for insert token\n",
    "            truncation=True,\n",
    "        )\n",
    "        encoding = _insert_token(encoding, insert_token_id)  # type: ignore\n",
    "        encoding = {key: value.to(self.device) for key, value in encoding.items()}\n",
    "        return encoding\n",
    "\n",
    "    def _query_encode(self, query: list[str]):\n",
    "        return self._encode(query, self.query_token_id)\n",
    "\n",
    "    def _document_encode(self, documents: list[str]):\n",
    "        return self._encode(documents, self.document_token_id)\n",
    "\n",
    "    def _to_embs(self, encoding) -> torch.Tensor:\n",
    "        with torch.no_grad():\n",
    "            embs = self.model(**encoding).last_hidden_state.squeeze(1)\n",
    "        if self.normalize:\n",
    "            embs = embs / embs.norm(dim=-1, keepdim=True)\n",
    "        return embs\n",
    "\n",
    "    def _rerank(self, query: str, documents: list[str]) -> list[float]:\n",
    "        query_encoding = self._query_encode([query])\n",
    "        documents_encoding = self._document_encode(documents)\n",
    "        query_embeddings = self._to_embs(query_encoding)\n",
    "        document_embeddings = self._to_embs(documents_encoding)\n",
    "        scores = (\n",
    "            _colbert_score(\n",
    "                query_embeddings,\n",
    "                document_embeddings,\n",
    "                query_encoding[\"attention_mask\"],\n",
    "                documents_encoding[\"attention_mask\"],\n",
    "            )\n",
    "            .cpu()\n",
    "            .tolist()[0]\n",
    "        )\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"colbert-ir/colbertv2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker = ColbertReranker(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is natural language processing?\"\n",
    "documents = [\n",
    "    \"Natural language processing enables computers to understand human language.\",\n",
    "    \"Machine learning involves teaching computers to learn from data.\",\n",
    "    \"The history of natural language processing is closely linked to the field of linguistics.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of q_reps, p_reps, q_mask, p_mask\n",
      "torch.Size([1, 9, 768]) torch.Size([3, 18, 768]) torch.Size([1, 9]) torch.Size([3, 18])\n",
      "tensor([[[-0.0202,  0.0142, -0.0175,  ..., -0.0148, -0.0366,  0.0108],\n",
      "         [-0.0149, -0.0103, -0.0072,  ...,  0.0144,  0.0254,  0.0212],\n",
      "         [-0.0472,  0.0152,  0.0272,  ...,  0.0078, -0.0006,  0.0309],\n",
      "         ...,\n",
      "         [ 0.0449, -0.0036,  0.0112,  ..., -0.0260, -0.0234, -0.0324],\n",
      "         [-0.0297, -0.0320,  0.0055,  ..., -0.0367, -0.0282, -0.0243],\n",
      "         [-0.0082,  0.0248, -0.0427,  ..., -0.0274, -0.0592, -0.0046]]],\n",
      "       device='cuda:0', dtype=torch.float16) tensor([[[-0.0314,  0.0219, -0.0083,  ..., -0.0190, -0.0556,  0.0139],\n",
      "         [-0.0259,  0.0394,  0.0102,  ...,  0.0078, -0.0348,  0.0133],\n",
      "         [-0.0047,  0.0051,  0.0015,  ...,  0.0262,  0.0074,  0.0116],\n",
      "         ...,\n",
      "         [-0.0087, -0.0051, -0.0146,  ...,  0.0090,  0.0162,  0.0319],\n",
      "         [-0.0292, -0.0147,  0.0010,  ..., -0.0268, -0.0195,  0.0202],\n",
      "         [-0.0259, -0.0113,  0.0009,  ..., -0.0312, -0.0242,  0.0171]],\n",
      "\n",
      "        [[ 0.0010,  0.0097, -0.0226,  ..., -0.0013, -0.0287,  0.0249],\n",
      "         [ 0.0206, -0.0011, -0.0028,  ...,  0.0136, -0.0197,  0.0358],\n",
      "         [ 0.0523, -0.0020, -0.0068,  ...,  0.0119, -0.0050,  0.0316],\n",
      "         ...,\n",
      "         [ 0.0270, -0.0197,  0.0196,  ...,  0.0115, -0.0121,  0.0326],\n",
      "         [ 0.0283, -0.0240,  0.0039,  ...,  0.0069, -0.0113,  0.0251],\n",
      "         [-0.0054, -0.0011, -0.0426,  ..., -0.0113, -0.0093,  0.0131]],\n",
      "\n",
      "        [[-0.0348,  0.0403, -0.0294,  ..., -0.0126, -0.0107,  0.0135],\n",
      "         [ 0.0047,  0.0266, -0.0057,  ...,  0.0328,  0.0048,  0.0328],\n",
      "         [-0.0076,  0.0325, -0.0356,  ...,  0.0034,  0.0146,  0.0396],\n",
      "         ...,\n",
      "         [-0.0505,  0.0690,  0.0157,  ..., -0.0355, -0.0049, -0.0128],\n",
      "         [-0.0259,  0.0446, -0.0449,  ..., -0.0002, -0.0299,  0.0087],\n",
      "         [-0.0242,  0.0389, -0.0394,  ...,  0.0035, -0.0311,  0.0073]]],\n",
      "       device='cuda:0', dtype=torch.float16) tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0') tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "indices, scores = reranker.rerank(query, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 Score: 0.9501953125\n",
      "Content: Machine learning involves teaching computers to learn from data.\n",
      "\n",
      "Document 2 Score: 0.587890625\n",
      "Content: The history of natural language processing is closely linked to the field of linguistics.\n",
      "\n",
      "Document 0 Score: 0.85693359375\n",
      "Content: Natural language processing enables computers to understand human language.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, score in zip(indices, scores):\n",
    "    print(f\"Document {idx} Score: {score}\")\n",
    "    print(f\"Content: {documents[idx]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
